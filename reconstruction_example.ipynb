{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Grid reconstruction\r\n",
    "\r\n",
    "Each image may have small rotations or areas that overlap with other input images that need to be considered when reconstructing the grid.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To reconstruct the grid, I try and get the biggest contour (grid pattern) on a processed image. Then I resize the contour and rotate the grid to get the output image. Finally, I put them together. Only the central part of the Neubauer chamber will be considered."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "import numpy as np\r\n",
    "import cv2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "DEBUG_RECONSTRUCTION = True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read image (note that any image of the dataset could be chosen. We will use 1Quad.jpg as an example)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "img = cv2.imread(\"./dataset/1Quad.jpg\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid reconstruction - Copy image, grayscale, and adaptive threshold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "image = img.copy()\r\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n",
    "thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 57, 5)\r\n",
    "if (DEBUG_RECONSTRUCTION): cv2.imwrite(\"thresh.jpg\", thresh)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generated Threshold image:\r\n",
    "![Threshold image](./thresh.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mathematical morphology - apply erosion, morph_close and erosion again to keep only (kinda) the grid"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "thresh = cv2.GaussianBlur(thresh, (7,7), 0)\r\n",
    "ret, thresh = cv2.threshold(thresh, 210, 255, 0)\r\n",
    "kernel = np.ones((3,3), np.uint8)\r\n",
    "morphed = cv2.erode(thresh, None, kernel, iterations=16)\r\n",
    "morphed = cv2.morphologyEx(morphed, cv2.MORPH_CLOSE, kernel, iterations=55)\r\n",
    "morphed = cv2.erode(morphed, None, kernel, iterations=10)\r\n",
    "if (DEBUG_RECONSTRUCTION): cv2.imwrite(\"morphed.jpg\", morphed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generated Morphed image:\r\n",
    "![Morphed image](./morphed.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we find the contours and get the biggest one (that should be the inner part of the Neubauer chamber)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "contours, hierarchy = cv2.findContours(morphed, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\r\n",
    "\r\n",
    "c = max(contours, key = cv2.contourArea)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have to rescale the contour due to the previously morph operations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "def scale_contour(cnt, scale):\r\n",
    "    M = cv2.moments(cnt)\r\n",
    "    cx = int(M['m10']/M['m00'])\r\n",
    "    cy = int(M['m01']/M['m00'])\r\n",
    "\r\n",
    "    cnt_norm = cnt - [cx, cy]\r\n",
    "    cnt_scaled = cnt_norm * scale\r\n",
    "    cnt_scaled = cnt_scaled + [cx, cy]\r\n",
    "    cnt_scaled = cnt_scaled.astype(np.int32)\r\n",
    "\r\n",
    "    return cnt_scaled\r\n",
    "\r\n",
    "# Resize contour to match real image\r\n",
    "c = scale_contour(c, 1.16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "But the image is still rotated. For this reason we need to get the corners of contour (otherwise we would not know how much rotation we need). Finally we crop them to the correct size."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "rect = cv2.minAreaRect(c)\r\n",
    "box = cv2.boxPoints(rect)\r\n",
    "box = np.int0(box)\r\n",
    "\r\n",
    "def crop_rect(img, rect):\r\n",
    "    center = rect[0]\r\n",
    "    size = rect[1]\r\n",
    "    angle = rect[2]\r\n",
    "    center, size = tuple(map(int, center)), tuple(map(int, size))\r\n",
    "\r\n",
    "    height, width = img.shape[0], img.shape[1]\r\n",
    "    if (DEBUG_RECONSTRUCTION): print(\"width: {}, height: {}\".format(width, height))\r\n",
    "\r\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1)\r\n",
    "    img_rot = cv2.warpAffine(img, M, (width, height))\r\n",
    "\r\n",
    "    img_crop = cv2.getRectSubPix(img_rot, size, center)\r\n",
    "\r\n",
    "    img_crop = cv2.rotate(img_crop, rotateCode=cv2.ROTATE_90_CLOCKWISE)\r\n",
    "\r\n",
    "    return img_crop, img_rot\r\n",
    "\r\n",
    "# Rotate and crop images\r\n",
    "img_crop, img_rot = crop_rect(img, rect)\r\n",
    "\r\n",
    "if (DEBUG_RECONSTRUCTION): cv2.imwrite(\"croped.jpg\", img_crop)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "width: 2000, height: 1431\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generated Rotated and croped image:\r\n",
    "\r\n",
    "![Rotated and croped image](./croped.jpg)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last step is to put all images together. For this we have a function that concat images vertically and horizontally."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def vertical_concat(im_list, interpolation=cv2.INTER_CUBIC):\r\n",
    "    w_min = min(im.shape[1] for im in im_list)\r\n",
    "    im_list_resize = [cv2.resize(im, (w_min, int(im.shape[0] * w_min / im.shape[1])), interpolation=interpolation) for im in im_list]\r\n",
    "    return cv2.vconcat(im_list_resize)\r\n",
    "\r\n",
    "def horizontal_concat(im_list, interpolation=cv2.INTER_CUBIC):\r\n",
    "    h_min = min(im.shape[0] for im in im_list)\r\n",
    "    im_list_resize = [cv2.resize(im, (int(im.shape[1] * h_min / im.shape[0]), h_min), interpolation=interpolation) for im in im_list]\r\n",
    "    return cv2.hconcat(im_list_resize)\r\n",
    "\r\n",
    "def concat(im_list_2d, interpolation=cv2.INTER_CUBIC):\r\n",
    "    im_list_v = [horizontal_concat(im_list_h, interpolation=cv2.INTER_CUBIC) for im_list_h in im_list_2d]\r\n",
    "    return vertical_concat(im_list_v, interpolation=cv2.INTER_CUBIC)\r\n",
    "\r\n",
    "reconstructed = concat([[img_crop, img_crop, img_crop, img_crop, img_crop],\r\n",
    "                        [img_crop, img_crop, img_crop, img_crop, img_crop],\r\n",
    "                        [img_crop, img_crop, img_crop, img_crop, img_crop],\r\n",
    "                        [img_crop, img_crop, img_crop, img_crop, img_crop],\r\n",
    "                        [img_crop, img_crop, img_crop, img_crop, img_crop]])\r\n",
    "\r\n",
    "if (DEBUG_RECONSTRUCTION): cv2.imwrite(\"reconstructed.jpg\", reconstructed)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We end up with the following reconstructed grid:\r\n",
    "![Reconstructed grid](./reconstructed.jpg)"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}